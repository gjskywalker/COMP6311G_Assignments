{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "210f00ef",
   "metadata": {},
   "source": [
    "#### Supervisor's Advice\n",
    "- **Higher Dimensions:** I suggest considering higher dimensions for this implementation. For instance, you could use **time** as a third attribute to evaluate the performance of different indices in accelerating query processing.\n",
    "- **Query Definition:** Please ensure that you formally define your queries in the Assignment 2 report.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48d227",
   "metadata": {},
   "source": [
    "### Project Flow\n",
    "\n",
    "**Dataset Preparation** $\\rightarrow$ **Algorithm Implementation** $\\rightarrow$ **Comparison Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bcfb56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def build_dataset(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file and constructs a dataset with Latitude and Longitude.\n",
    "    Returns None if the dataset cannot be built.\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "\n",
    "    # Extract latitude and longitude columns\n",
    "    # Note: The actual column names in the CSV file are 'decimalLatitude' and 'decimalLongitude' (starting with lowercase)\n",
    "    required_columns = ['decimalLatitude', 'decimalLongitude']\n",
    "\n",
    "    # Read CSV file with only specific columns to avoid DtypeWarning and save memory\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, usecols=required_columns)\n",
    "        \n",
    "        # Construct dataset containing only latitude and longitude, and remove null values\n",
    "        dataset = df.dropna()\n",
    "        \n",
    "        # Rename columns for easier use later (optional)\n",
    "        dataset.columns = ['Latitude', 'Longitude']\n",
    "        \n",
    "        print(\"Dataset constructed successfully.\")\n",
    "        print(dataset.head())\n",
    "        print(f\"\\nShape of dataset: {dataset.shape}\")\n",
    "        return dataset\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Error reading columns: {e}\")\n",
    "        # Fallback to reading just the header to show available columns\n",
    "        try:\n",
    "            df_header = pd.read_csv(file_path, nrows=0)\n",
    "            print(f\"Available columns: {df_header.columns.tolist()}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b9ed8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset constructed successfully.\n",
      "    Latitude   Longitude\n",
      "0 -34.283333  119.450000\n",
      "1 -38.155730  144.293950\n",
      "2 -38.150160  144.301090\n",
      "3 -38.082467  144.281096\n",
      "4 -38.147793  144.311988\n",
      "\n",
      "Shape of dataset: (29656, 2)\n",
      "Dataset constructed successfully.\n",
      "    Latitude   Longitude\n",
      "0 -33.756980  150.628200\n",
      "1 -33.601780  150.829319\n",
      "2 -33.740972  150.741930\n",
      "3 -34.170950  150.612113\n",
      "4 -33.762350  150.831433\n",
      "\n",
      "Shape of dataset: (1454283, 2)\n",
      "Dataset constructed successfully.\n",
      "    Latitude   Longitude\n",
      "0 -33.756980  150.628200\n",
      "1 -33.601780  150.829319\n",
      "2 -33.740972  150.741930\n",
      "3 -34.170950  150.612113\n",
      "4 -33.762350  150.831433\n",
      "\n",
      "Shape of dataset: (1454283, 2)\n"
     ]
    }
   ],
   "source": [
    "# Build Platypus dataset\n",
    "platypus_file_path = 'Dataset/Platypus/Platypus.csv'\n",
    "platypus_dataset = build_dataset(platypus_file_path)\n",
    "\n",
    "# Build Legless Lizard dataset\n",
    "legless_file_path = 'Dataset/Legless_Lizards/Legless_Lizards.csv'\n",
    "legless_dataset = build_dataset(legless_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f873177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building Protected Areas Dataset ---\n",
      "Layers found in data.gdb: ['Protected_areas']\n",
      "Reading layer: 'Protected_areas'...\n",
      "Dataset constructed successfully.\n",
      "Shape: (2214, 26)\n",
      "Geometry Type: ['MultiPolygon']\n",
      "CRS (Coordinate Reference System): EPSG:7844\n",
      "  lot     plan   lotplans  sysintcode                   estatename  \\\n",
      "0  28    SB653    28SB653  0691ABB001  Abbot Bay Conservation Park   \n",
      "1   1  AP22467   1AP22467  3336ABE001      Abergowrie State Forest   \n",
      "2   2  AP22467   2AP22467  3336ABE001      Abergowrie State Forest   \n",
      "3   5  AP22467   5AP22467  3336ABE001      Abergowrie State Forest   \n",
      "4  10  AP22467  10AP22467  3336ABE001      Abergowrie State Forest   \n",
      "\n",
      "      nameabbrev                     namecaps esttype     dcdbtenure  \\\n",
      "0   Abbot Bay CP  ABBOT BAY CONSERVATION PARK      CP  National Park   \n",
      "1  Abergowrie SF      ABERGOWRIE STATE FOREST      SF   State Forest   \n",
      "2  Abergowrie SF      ABERGOWRIE STATE FOREST      SF   State Forest   \n",
      "3  Abergowrie SF      ABERGOWRIE STATE FOREST      SF   State Forest   \n",
      "4  Abergowrie SF      ABERGOWRIE STATE FOREST      SF   State Forest   \n",
      "\n",
      "                     legislated  ...                curgazdate  \\\n",
      "0  Nature Conservation Act 1992  ... 2019-04-19 00:00:00+00:00   \n",
      "1             Forestry Act 1959  ... 2019-04-19 00:00:00+00:00   \n",
      "2             Forestry Act 1959  ... 2019-04-19 00:00:00+00:00   \n",
      "3             Forestry Act 1959  ... 2019-04-19 00:00:00+00:00   \n",
      "4             Forestry Act 1959  ... 2019-04-19 00:00:00+00:00   \n",
      "\n",
      "                origgazdate   latitude   longitude zone    modleg  \\\n",
      "0 1994-08-12 00:00:00+00:00 -19.922441  147.964959   55  DEC-2019   \n",
      "1 1995-10-06 00:00:00+00:00 -18.425505  145.865906   55  DEC-2019   \n",
      "2 1995-10-06 00:00:00+00:00 -18.417460  145.945132   55  DEC-2019   \n",
      "3 1995-10-06 00:00:00+00:00 -18.469585  146.004247   55  DEC-2019   \n",
      "4 1995-10-06 00:00:00+00:00 -18.499477  146.065686   55  DEC-2019   \n",
      "\n",
      "                   dcdbused shape_Length    shape_Area  \\\n",
      "0 2025-10-27 00:00:00+00:00     0.069999  1.244614e-04   \n",
      "1 2025-10-27 00:00:00+00:00     0.031871  4.315549e-05   \n",
      "2 2025-10-27 00:00:00+00:00     0.030403  4.192861e-05   \n",
      "3 2025-10-27 00:00:00+00:00     0.004528  6.217903e-07   \n",
      "4 2025-10-27 00:00:00+00:00     0.014948  1.026139e-05   \n",
      "\n",
      "                                            geometry  \n",
      "0  MULTIPOLYGON (((147.95192 -19.91701, 147.95278...  \n",
      "1  MULTIPOLYGON (((145.86099 -18.42249, 145.86167...  \n",
      "2  MULTIPOLYGON (((145.94091 -18.41845, 145.94115...  \n",
      "3  MULTIPOLYGON (((146.00488 -18.46874, 146.00449...  \n",
      "4  MULTIPOLYGON (((146.06504 -18.49792, 146.06893...  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "--- Building Wetlands Dataset ---\n",
      "Layers found in data.gdb: ['Directory_of_important_wetlands']\n",
      "Reading layer: 'Directory_of_important_wetlands'...\n",
      "Dataset constructed successfully.\n",
      "Shape: (335, 20)\n",
      "Geometry Type: ['MultiPolygon']\n",
      "CRS (Coordinate Reference System): EPSG:4283\n",
      "                                     wet_aggr        area_ha      aggr_area  \\\n",
      "0               Palm Tree and Robinson Creeks   50222.533335   50222.533335   \n",
      "1                          Great Sandy Strait   92000.082911   92000.082911   \n",
      "2     Cooper Creek Overflow Swamps - Windorah  124892.637565  124892.637565   \n",
      "3                           Boggomoss Springs     398.755572     398.755572   \n",
      "4  Diamantina Overflow Swamp - Durrie Station   29216.684968   29216.684968   \n",
      "\n",
      "  ancacode                 location  bgr     feat_code refcode  \\\n",
      "0    BBS08         28km N of Taroom  BBS  watercours_l  QLD018   \n",
      "1    SEQ09  20km ESE of Maryborough  SEQ  watercours_a  QLD132   \n",
      "2    CHC03      65km SW of Windorah  CHC  sub_to_inund  QLD025   \n",
      "3    BBS01        20km NE of Taroom  BBS          lake  QLD010   \n",
      "4    CHC07        35km W of Betoota  CHC  sub_to_inund  QLD029   \n",
      "\n",
      "                                        wname  \\\n",
      "0               Palm Tree and Robinson Creeks   \n",
      "1                          Great Sandy Strait   \n",
      "2     Cooper Creek Overflow Swamps - Windorah   \n",
      "3                           Boggomoss Springs   \n",
      "4  Diamantina Overflow Swamp - Durrie Station   \n",
      "\n",
      "                                source state  date_suppl  updated  code  \\\n",
      "0  Auslig topo 1:250 000 and 1:100 000   QLD      2005.0   1995.0   197   \n",
      "1  Auslig topo 1:250 000 and 1:100 000   QLD      2005.0   2004.0   198   \n",
      "2  Auslig topo 1:250 000 and 1:100 000   QLD      2005.0   2004.0   199   \n",
      "3  Auslig topo 1:250 000 and 1:100 000   QLD      2005.0   2004.0   200   \n",
      "4  Auslig topo 1:250 000 and 1:100 000   QLD      2005.0   2002.0   201   \n",
      "\n",
      "   original aggr_code                                  features  shape_Length  \\\n",
      "0    1992.0    QLD018                 watercours_l, lake, swamp      3.577776   \n",
      "1    1995.0    QLD132  watercours_a, mangrove_flt, saln_cst_flt      4.241146   \n",
      "2    1995.0    QLD025                              sub_to_inund      1.498717   \n",
      "3    1995.0    QLD010                                      lake      0.067194   \n",
      "4    1995.0    QLD029                        sub_to_inund, lake      0.648894   \n",
      "\n",
      "   shape_Area                                           geometry  \n",
      "0    0.045049  MULTIPOLYGON (((149.62731 -25.24781, 149.62751...  \n",
      "1    0.082629  MULTIPOLYGON (((153.00366 -25.2169, 153.00421 ...  \n",
      "2    0.112222  MULTIPOLYGON (((142.49661 -25.63513, 142.4951 ...  \n",
      "3    0.000358  MULTIPOLYGON (((150.17899 -25.41534, 150.17883...  \n",
      "4    0.026262  MULTIPOLYGON (((140.30363 -25.6289, 140.30793 ...  \n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "def build_polygon_dataset(gdb_path: str, layer_name: str = None) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Reads a GDB file and constructs a GeoDataFrame containing polygons.\n",
    "    If layer_name is not provided, reads the first layer found.\n",
    "    \"\"\"\n",
    "    # Check if the GDB directory exists\n",
    "    if not os.path.exists(gdb_path):\n",
    "        print(f\"Error: GDB not found at {gdb_path}\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        # List all layers in the GDB to understand the structure\n",
    "        layers = fiona.listlayers(gdb_path)\n",
    "        print(f\"Layers found in {os.path.basename(gdb_path)}: {layers}\")\n",
    "        \n",
    "        if not layers:\n",
    "            print(\"Error: No layers found in the GDB.\")\n",
    "            return None\n",
    "            \n",
    "        # Determine which layer to read (default to the first one if not specified)\n",
    "        target_layer = layer_name if layer_name else layers[0]\n",
    "        \n",
    "        if target_layer not in layers:\n",
    "             print(f\"Error: Layer '{target_layer}' not found in GDB.\")\n",
    "             return None\n",
    "             \n",
    "        print(f\"Reading layer: '{target_layer}'...\")\n",
    "        \n",
    "        # Read the layer into a GeoDataFrame\n",
    "        gdf = gpd.read_file(gdb_path, layer=target_layer)\n",
    "        \n",
    "        print(\"Dataset constructed successfully.\")\n",
    "        print(f\"Shape: {gdf.shape}\")\n",
    "        print(f\"Geometry Type: {gdf.geom_type.unique()}\")\n",
    "        print(f\"CRS (Coordinate Reference System): {gdf.crs}\")\n",
    "        print(gdf.head())\n",
    "        return gdf\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"Error: 'geopandas' or 'fiona' library is not installed. Please install them using 'pip install geopandas fiona'.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the GDB: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define paths to the GDB files\n",
    "protected_areas_gdb = 'Dataset/Protected_Areas_of_Queensland/data.gdb'\n",
    "wetlands_gdb = 'Dataset/Wetlands_data_QueenLand/data.gdb'\n",
    "\n",
    "# Build the datasets\n",
    "print(\"--- Building Protected Areas Dataset ---\")\n",
    "protected_areas_gdf = build_polygon_dataset(protected_areas_gdb)\n",
    "\n",
    "print(\"\\n--- Building Wetlands Dataset ---\")\n",
    "wetlands_gdf = build_polygon_dataset(wetlands_gdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e7878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
