{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "210f00ef",
   "metadata": {},
   "source": [
    "#### Supervisor's Advice\n",
    "- **Higher Dimensions:** I suggest considering higher dimensions for this implementation. For instance, you could use **time** as a third attribute to evaluate the performance of different indices in accelerating query processing.\n",
    "- **Query Definition:** Please ensure that you formally define your queries in the Assignment 2 report.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48d227",
   "metadata": {},
   "source": [
    "#### Project Flow\n",
    "\n",
    "**Dataset Preparation** $\\rightarrow$ **Algorithm Implementation** $\\rightarrow$ **Comparison Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2bcfb56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def build_dataset(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file and constructs a dataset with Latitude and Longitude.\n",
    "    Returns None if the dataset cannot be built.\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "\n",
    "    # Extract latitude and longitude columns\n",
    "    # Note: The actual column names in the CSV file are 'decimalLatitude' and 'decimalLongitude' (starting with lowercase)\n",
    "    required_columns = ['decimalLatitude', 'decimalLongitude']\n",
    "\n",
    "    # Read CSV file with only specific columns to avoid DtypeWarning and save memory\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, usecols=required_columns)\n",
    "        \n",
    "        # Construct dataset containing only latitude and longitude, and remove null values\n",
    "        dataset = df.dropna()\n",
    "        \n",
    "        # Rename columns for easier use later (optional)\n",
    "        dataset.columns = ['Latitude', 'Longitude']\n",
    "        \n",
    "        print(\"Dataset constructed successfully.\")\n",
    "        print(dataset.head())\n",
    "        print(f\"\\nShape of dataset: {dataset.shape}\")\n",
    "        return dataset\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Error reading columns: {e}\")\n",
    "        # Fallback to reading just the header to show available columns\n",
    "        try:\n",
    "            df_header = pd.read_csv(file_path, nrows=0)\n",
    "            print(f\"Available columns: {df_header.columns.tolist()}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b9ed8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset constructed successfully.\n",
      "    Latitude   Longitude\n",
      "0 -34.283333  119.450000\n",
      "1 -38.155730  144.293950\n",
      "2 -38.150160  144.301090\n",
      "3 -38.082467  144.281096\n",
      "4 -38.147793  144.311988\n",
      "\n",
      "Shape of dataset: (29656, 2)\n",
      "Dataset constructed successfully.\n",
      "    Latitude   Longitude\n",
      "0 -33.756980  150.628200\n",
      "1 -33.601780  150.829319\n",
      "2 -33.740972  150.741930\n",
      "3 -34.170950  150.612113\n",
      "4 -33.762350  150.831433\n",
      "\n",
      "Shape of dataset: (1454283, 2)\n",
      "Dataset constructed successfully.\n",
      "    Latitude   Longitude\n",
      "0 -33.756980  150.628200\n",
      "1 -33.601780  150.829319\n",
      "2 -33.740972  150.741930\n",
      "3 -34.170950  150.612113\n",
      "4 -33.762350  150.831433\n",
      "\n",
      "Shape of dataset: (1454283, 2)\n"
     ]
    }
   ],
   "source": [
    "# Build Platypus dataset\n",
    "platypus_file_path = 'Dataset/Platypus/Platypus.csv'\n",
    "platypus_dataset = build_dataset(platypus_file_path)\n",
    "\n",
    "# Build Legless Lizard dataset\n",
    "legless_file_path = 'Dataset/Legless_Lizards/Legless_Lizards.csv'\n",
    "legless_dataset = build_dataset(legless_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3660f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install geopandas fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0f873177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building Protected Areas Dataset ---\n",
      "Layers found in data.gdb: ['Protected_areas']\n",
      "Reading layer: 'Protected_areas'...\n",
      "Dataset constructed successfully.\n",
      "Shape: (2214, 26)\n",
      "Geometry Type: ['MultiPolygon']\n",
      "CRS (Coordinate Reference System): EPSG:7844\n",
      "  lot     plan   lotplans  sysintcode                   estatename  \\\n",
      "0  28    SB653    28SB653  0691ABB001  Abbot Bay Conservation Park   \n",
      "1   1  AP22467   1AP22467  3336ABE001      Abergowrie State Forest   \n",
      "2   2  AP22467   2AP22467  3336ABE001      Abergowrie State Forest   \n",
      "3   5  AP22467   5AP22467  3336ABE001      Abergowrie State Forest   \n",
      "4  10  AP22467  10AP22467  3336ABE001      Abergowrie State Forest   \n",
      "\n",
      "      nameabbrev                     namecaps esttype     dcdbtenure  \\\n",
      "0   Abbot Bay CP  ABBOT BAY CONSERVATION PARK      CP  National Park   \n",
      "1  Abergowrie SF      ABERGOWRIE STATE FOREST      SF   State Forest   \n",
      "2  Abergowrie SF      ABERGOWRIE STATE FOREST      SF   State Forest   \n",
      "3  Abergowrie SF      ABERGOWRIE STATE FOREST      SF   State Forest   \n",
      "4  Abergowrie SF      ABERGOWRIE STATE FOREST      SF   State Forest   \n",
      "\n",
      "                     legislated  ...                curgazdate  \\\n",
      "0  Nature Conservation Act 1992  ... 2019-04-19 00:00:00+00:00   \n",
      "1             Forestry Act 1959  ... 2019-04-19 00:00:00+00:00   \n",
      "2             Forestry Act 1959  ... 2019-04-19 00:00:00+00:00   \n",
      "3             Forestry Act 1959  ... 2019-04-19 00:00:00+00:00   \n",
      "4             Forestry Act 1959  ... 2019-04-19 00:00:00+00:00   \n",
      "\n",
      "                origgazdate   latitude   longitude zone    modleg  \\\n",
      "0 1994-08-12 00:00:00+00:00 -19.922441  147.964959   55  DEC-2019   \n",
      "1 1995-10-06 00:00:00+00:00 -18.425505  145.865906   55  DEC-2019   \n",
      "2 1995-10-06 00:00:00+00:00 -18.417460  145.945132   55  DEC-2019   \n",
      "3 1995-10-06 00:00:00+00:00 -18.469585  146.004247   55  DEC-2019   \n",
      "4 1995-10-06 00:00:00+00:00 -18.499477  146.065686   55  DEC-2019   \n",
      "\n",
      "                   dcdbused shape_Length    shape_Area  \\\n",
      "0 2025-10-27 00:00:00+00:00     0.069999  1.244614e-04   \n",
      "1 2025-10-27 00:00:00+00:00     0.031871  4.315549e-05   \n",
      "2 2025-10-27 00:00:00+00:00     0.030403  4.192861e-05   \n",
      "3 2025-10-27 00:00:00+00:00     0.004528  6.217903e-07   \n",
      "4 2025-10-27 00:00:00+00:00     0.014948  1.026139e-05   \n",
      "\n",
      "                                            geometry  \n",
      "0  MULTIPOLYGON (((147.95192 -19.91701, 147.95278...  \n",
      "1  MULTIPOLYGON (((145.86099 -18.42249, 145.86167...  \n",
      "2  MULTIPOLYGON (((145.94091 -18.41845, 145.94115...  \n",
      "3  MULTIPOLYGON (((146.00488 -18.46874, 146.00449...  \n",
      "4  MULTIPOLYGON (((146.06504 -18.49792, 146.06893...  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "--- Building Wetlands Dataset ---\n",
      "Layers found in data.gdb: ['Directory_of_important_wetlands']\n",
      "Reading layer: 'Directory_of_important_wetlands'...\n",
      "Dataset constructed successfully.\n",
      "Shape: (335, 20)\n",
      "Geometry Type: ['MultiPolygon']\n",
      "CRS (Coordinate Reference System): EPSG:4283\n",
      "                                     wet_aggr        area_ha      aggr_area  \\\n",
      "0               Palm Tree and Robinson Creeks   50222.533335   50222.533335   \n",
      "1                          Great Sandy Strait   92000.082911   92000.082911   \n",
      "2     Cooper Creek Overflow Swamps - Windorah  124892.637565  124892.637565   \n",
      "3                           Boggomoss Springs     398.755572     398.755572   \n",
      "4  Diamantina Overflow Swamp - Durrie Station   29216.684968   29216.684968   \n",
      "\n",
      "  ancacode                 location  bgr     feat_code refcode  \\\n",
      "0    BBS08         28km N of Taroom  BBS  watercours_l  QLD018   \n",
      "1    SEQ09  20km ESE of Maryborough  SEQ  watercours_a  QLD132   \n",
      "2    CHC03      65km SW of Windorah  CHC  sub_to_inund  QLD025   \n",
      "3    BBS01        20km NE of Taroom  BBS          lake  QLD010   \n",
      "4    CHC07        35km W of Betoota  CHC  sub_to_inund  QLD029   \n",
      "\n",
      "                                        wname  \\\n",
      "0               Palm Tree and Robinson Creeks   \n",
      "1                          Great Sandy Strait   \n",
      "2     Cooper Creek Overflow Swamps - Windorah   \n",
      "3                           Boggomoss Springs   \n",
      "4  Diamantina Overflow Swamp - Durrie Station   \n",
      "\n",
      "                                source state  date_suppl  updated  code  \\\n",
      "0  Auslig topo 1:250 000 and 1:100 000   QLD      2005.0   1995.0   197   \n",
      "1  Auslig topo 1:250 000 and 1:100 000   QLD      2005.0   2004.0   198   \n",
      "2  Auslig topo 1:250 000 and 1:100 000   QLD      2005.0   2004.0   199   \n",
      "3  Auslig topo 1:250 000 and 1:100 000   QLD      2005.0   2004.0   200   \n",
      "4  Auslig topo 1:250 000 and 1:100 000   QLD      2005.0   2002.0   201   \n",
      "\n",
      "   original aggr_code                                  features  shape_Length  \\\n",
      "0    1992.0    QLD018                 watercours_l, lake, swamp      3.577776   \n",
      "1    1995.0    QLD132  watercours_a, mangrove_flt, saln_cst_flt      4.241146   \n",
      "2    1995.0    QLD025                              sub_to_inund      1.498717   \n",
      "3    1995.0    QLD010                                      lake      0.067194   \n",
      "4    1995.0    QLD029                        sub_to_inund, lake      0.648894   \n",
      "\n",
      "   shape_Area                                           geometry  \n",
      "0    0.045049  MULTIPOLYGON (((149.62731 -25.24781, 149.62751...  \n",
      "1    0.082629  MULTIPOLYGON (((153.00366 -25.2169, 153.00421 ...  \n",
      "2    0.112222  MULTIPOLYGON (((142.49661 -25.63513, 142.4951 ...  \n",
      "3    0.000358  MULTIPOLYGON (((150.17899 -25.41534, 150.17883...  \n",
      "4    0.026262  MULTIPOLYGON (((140.30363 -25.6289, 140.30793 ...  \n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "def build_polygon_dataset(gdb_path: str, layer_name: str = None) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Reads a GDB file and constructs a GeoDataFrame containing polygons.\n",
    "    If layer_name is not provided, reads the first layer found.\n",
    "    \"\"\"\n",
    "    # Check if the GDB directory exists\n",
    "    if not os.path.exists(gdb_path):\n",
    "        print(f\"Error: GDB not found at {gdb_path}\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        # List all layers in the GDB to understand the structure\n",
    "        layers = fiona.listlayers(gdb_path)\n",
    "        print(f\"Layers found in {os.path.basename(gdb_path)}: {layers}\")\n",
    "        \n",
    "        if not layers:\n",
    "            print(\"Error: No layers found in the GDB.\")\n",
    "            return None\n",
    "            \n",
    "        # Determine which layer to read (default to the first one if not specified)\n",
    "        target_layer = layer_name if layer_name else layers[0]\n",
    "        \n",
    "        if target_layer not in layers:\n",
    "             print(f\"Error: Layer '{target_layer}' not found in GDB.\")\n",
    "             return None\n",
    "             \n",
    "        print(f\"Reading layer: '{target_layer}'...\")\n",
    "        \n",
    "        # Read the layer into a GeoDataFrame\n",
    "        gdf = gpd.read_file(gdb_path, layer=target_layer)\n",
    "        \n",
    "        print(\"Dataset constructed successfully.\")\n",
    "        print(f\"Shape: {gdf.shape}\")\n",
    "        print(f\"Geometry Type: {gdf.geom_type.unique()}\")\n",
    "        print(f\"CRS (Coordinate Reference System): {gdf.crs}\")\n",
    "        print(gdf.head())\n",
    "        return gdf\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"Error: 'geopandas' or 'fiona' library is not installed. Please install them using 'pip install geopandas fiona'.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the GDB: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define paths to the GDB files\n",
    "protected_areas_gdb = 'Dataset/Protected_Areas_of_Queensland/data.gdb'\n",
    "wetlands_gdb = 'Dataset/Wetlands_data_QueenLand/data.gdb'\n",
    "\n",
    "# Build the datasets\n",
    "print(\"--- Building Protected Areas Dataset ---\")\n",
    "protected_areas_gdf = build_polygon_dataset(protected_areas_gdb)\n",
    "\n",
    "print(\"\\n--- Building Wetlands Dataset ---\")\n",
    "wetlands_gdf = build_polygon_dataset(wetlands_gdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e4a50",
   "metadata": {},
   "source": [
    "### Query Definitions (SQL-like)\n",
    "\n",
    "**(1) Find the number of sightings of legless lizards in Pine Ridge Conservation Park.**\n",
    "```sql\n",
    "SELECT COUNT(*) \n",
    "FROM LeglessLizards AS L \n",
    "JOIN ProtectedAreas AS P ON ST_Contains(P.geometry, L.geometry) \n",
    "WHERE P.estatename = 'Pine Ridge Conservation Park';\n",
    "```\n",
    "\n",
    "**(2) Find all wetlands inside a state or national forest park.**\n",
    "```sql\n",
    "SELECT W.* \n",
    "FROM Wetlands AS W \n",
    "JOIN ProtectedAreas AS P ON ST_Within(W.geometry, P.geometry) \n",
    "WHERE P.dcdbtenure IN ('State Forest', 'National Park');\n",
    "```\n",
    "\n",
    "**(3) Find all sightings of platypus and the distance to the closest wetlands (set the distance to 0 if the sighting is inside a wetland).**\n",
    "```sql\n",
    "SELECT P.*, MIN(ST_Distance(P.geometry, W.geometry)) AS distance_to_wetland\n",
    "FROM Platypus AS P\n",
    "CROSS JOIN Wetlands AS W\n",
    "GROUP BY P.id;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "687eec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reprojecting datasets to EPSG:3577...\n",
      "Preprocessing complete.\n",
      "Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Data Preprocessing ---\n",
    "\n",
    "# 1. Convert CSV DataFrames to GeoDataFrames\n",
    "# Assuming the CSV coordinates are in WGS84 (EPSG:4326)\n",
    "legless_gdf = gpd.GeoDataFrame(\n",
    "    legless_dataset, \n",
    "    geometry=gpd.points_from_xy(legless_dataset.Longitude, legless_dataset.Latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "platypus_gdf = gpd.GeoDataFrame(\n",
    "    platypus_dataset, \n",
    "    geometry=gpd.points_from_xy(platypus_dataset.Longitude, platypus_dataset.Latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# 2. Reproject all datasets to a common projected CRS for accurate spatial operations (e.g., distance)\n",
    "# EPSG:3577 (GDA94 / Australian Albers) is a good choice for Australia-wide data\n",
    "target_crs = \"EPSG:3577\"\n",
    "\n",
    "print(\"Reprojecting datasets to EPSG:3577...\")\n",
    "legless_gdf = legless_gdf.to_crs(target_crs)\n",
    "platypus_gdf = platypus_gdf.to_crs(target_crs)\n",
    "protected_areas_gdf = protected_areas_gdf.to_crs(target_crs)\n",
    "wetlands_gdf = wetlands_gdf.to_crs(target_crs)\n",
    "\n",
    "print(\"Preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f0e5a87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 18 duplicate sightings.\n",
      "Query 1 Result: Number of legless lizard sightings in Pine Ridge Conservation Park: 14\n",
      "Results saved to Results/GPD/Query1_Lizards_in_PineRidge.csv\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'Results/GPD'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# --- Query 1: Number of sightings of legless lizards in Pine Ridge Conservation Park ---\n",
    "\n",
    "# Filter for the specific park\n",
    "pine_ridge_park = protected_areas_gdf[protected_areas_gdf['estatename'] == 'Pine Ridge Conservation Park']\n",
    "\n",
    "if not pine_ridge_park.empty:\n",
    "    # Perform spatial join: Find points WITHIN the polygon\n",
    "    # predicate='within' checks if the point is inside the polygon\n",
    "    lizards_in_park = gpd.sjoin(legless_gdf, pine_ridge_park, how='inner', predicate='within')\n",
    "    \n",
    "    # Remove duplicates based on Latitude and Longitude\n",
    "    initial_count = len(lizards_in_park)\n",
    "    lizards_in_park = lizards_in_park.drop_duplicates(subset=['Latitude', 'Longitude'])\n",
    "    count_lizards = len(lizards_in_park)\n",
    "    \n",
    "    if initial_count > count_lizards:\n",
    "        print(f\"Removed {initial_count - count_lizards} duplicate sightings.\")\n",
    "    \n",
    "    print(f\"Query 1 Result: Number of legless lizard sightings in Pine Ridge Conservation Park: {count_lizards}\")\n",
    "\n",
    "    # Save the result to a CSV file\n",
    "    output_file = os.path.join(output_dir, 'Query1_Lizards_in_PineRidge.csv')\n",
    "    lizards_in_park[['Latitude', 'Longitude']].to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "else:\n",
    "    print(\"Query 1 Error: 'Pine Ridge Conservation Park' not found in the protected areas dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "06b63d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 5 duplicate wetlands.\n",
      "Query 2 Result: Found 11 wetlands inside State or National Forest Parks.\n",
      "                    wname                                         estatename  \\\n",
      "66  Hilda Creek Headwater  Daintree National Park (Cape York Peninsula Ab...   \n",
      "79           Lake Barrine                         Crater Lakes National Park   \n",
      "81            Lake Eacham                         Crater Lakes National Park   \n",
      "82         Nandroya Falls                         Wooroonooran National Park   \n",
      "86  Diamantina Lakes Area                           Diamantina National Park   \n",
      "\n",
      "       dcdbtenure  \n",
      "66  National Park  \n",
      "79  National Park  \n",
      "81  National Park  \n",
      "82  National Park  \n",
      "86  National Park  \n",
      "Results saved to Results/GPD/Query2_Wetlands_in_Parks.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Query 2: Find all wetlands inside a state or national forest park ---\n",
    "\n",
    "# Filter for State Forest or National Park\n",
    "# Note: Checking 'dcdbtenure' column based on previous output inspection\n",
    "target_parks = protected_areas_gdf[protected_areas_gdf['dcdbtenure'].isin(['State Forest', 'National Park'])]\n",
    "\n",
    "# Perform spatial join: Find wetlands WITHIN the target parks\n",
    "# predicate='within' checks if the wetland geometry is completely inside the park geometry\n",
    "wetlands_in_parks = gpd.sjoin(wetlands_gdf, target_parks, how='inner', predicate='within')\n",
    "\n",
    "# Remove duplicates based on wetland name (wname)\n",
    "initial_count = len(wetlands_in_parks)\n",
    "wetlands_in_parks = wetlands_in_parks.drop_duplicates(subset=['wname'])\n",
    "final_count = len(wetlands_in_parks)\n",
    "\n",
    "if initial_count > final_count:\n",
    "    print(f\"Removed {initial_count - final_count} duplicate wetlands.\")\n",
    "\n",
    "print(f\"Query 2 Result: Found {final_count} wetlands inside State or National Forest Parks.\")\n",
    "print(wetlands_in_parks[['wname', 'estatename', 'dcdbtenure']].head())\n",
    "\n",
    "# Save the result to a CSV file\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, 'Query2_Wetlands_in_Parks.csv')\n",
    "wetlands_in_parks[['wname', 'estatename', 'dcdbtenure']].to_csv(output_file, index=False)\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5ad2248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 6260 duplicate platypus sightings.\n",
      "Query 3 Result: Calculated distance to closest wetland for all platypus sightings.\n",
      "    Latitude   Longitude                 wname  Distance (m)\n",
      "0 -34.283333  119.450000  Muncoonie Lakes Area  2.083351e+06\n",
      "1 -38.155730  144.293950           Bulloo Lake  1.032990e+06\n",
      "2 -38.150160  144.301090           Bulloo Lake  1.032487e+06\n",
      "3 -38.082467  144.281096           Bulloo Lake  1.024839e+06\n",
      "4 -38.147793  144.311988           Bulloo Lake  1.032387e+06\n",
      "Results saved to Results/GPD/Query3_Platypus_Nearest_Wetland.csv\n",
      "\n",
      "Number of sightings inside a wetland: 46\n"
     ]
    }
   ],
   "source": [
    "# --- Query 3: Find all sightings of platypus and the distance to the closest wetlands ---\n",
    "\n",
    "# Use sjoin_nearest to find the nearest wetland for each platypus sighting\n",
    "# distance_col='Distance (m)' will store the calculated distance\n",
    "# If the point is inside a wetland, the distance will be 0\n",
    "platypus_with_distance = gpd.sjoin_nearest(\n",
    "    platypus_gdf, \n",
    "    wetlands_gdf, \n",
    "    how='left', \n",
    "    distance_col='Distance (m)'\n",
    ")\n",
    "\n",
    "# Remove duplicates based on Latitude and Longitude\n",
    "initial_count = len(platypus_with_distance)\n",
    "platypus_with_distance = platypus_with_distance.drop_duplicates(subset=['Latitude', 'Longitude'])\n",
    "final_count = len(platypus_with_distance)\n",
    "\n",
    "if initial_count > final_count:\n",
    "    print(f\"Removed {initial_count - final_count} duplicate platypus sightings.\")\n",
    "\n",
    "print(\"Query 3 Result: Calculated distance to closest wetland for all platypus sightings.\")\n",
    "# Display relevant columns: Latitude, Longitude (original), and the calculated distance\n",
    "print(platypus_with_distance[['Latitude', 'Longitude', 'wname', 'Distance (m)']].head())\n",
    "\n",
    "# Save the result to a CSV file\n",
    "output_file = os.path.join(output_dir, 'Query3_Platypus_Nearest_Wetland.csv')\n",
    "platypus_with_distance[['Latitude', 'Longitude', 'wname', 'Distance (m)']].to_csv(output_file, index=False)\n",
    "print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Optional: Check if any are inside (distance == 0)\n",
    "inside_count = len(platypus_with_distance[platypus_with_distance['Distance (m)'] == 0])\n",
    "print(f\"\\nNumber of sightings inside a wetland: {inside_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fc479ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadTree class defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Custom QuadTree Implementation ---\n",
    "\n",
    "class Rect:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "    \n",
    "    def intersects(self, other):\n",
    "        return not (other.xmin > self.xmax or other.xmax < self.xmin or\n",
    "                    other.ymin > self.ymax or other.ymax < self.ymin)\n",
    "    \n",
    "    def contains_point(self, x, y):\n",
    "        return self.xmin <= x <= self.xmax and self.ymin <= y <= self.ymax\n",
    "\n",
    "    def contains_rect(self, other):\n",
    "        return (self.xmin <= other.xmin and self.xmax >= other.xmax and\n",
    "                self.ymin <= other.ymin and self.ymax >= other.ymax)\n",
    "\n",
    "class QuadTree:\n",
    "    # Increased max_depth from 10 to 20 to handle 1.45 million points efficiently\n",
    "    # Depth 20 provides much finer granularity for clustered data\n",
    "    def __init__(self, boundary, capacity=4, depth=0, max_depth=20):\n",
    "        self.boundary = boundary  # Rect\n",
    "        self.capacity = capacity\n",
    "        self.objects = []  # List of tuples (geometry, data_index/id)\n",
    "        self.divided = False\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        # Children\n",
    "        self.nw = None\n",
    "        self.ne = None\n",
    "        self.sw = None\n",
    "        self.se = None\n",
    "\n",
    "    def subdivide(self):\n",
    "        x_mid = (self.boundary.xmin + self.boundary.xmax) / 2\n",
    "        y_mid = (self.boundary.ymin + self.boundary.ymax) / 2\n",
    "        \n",
    "        self.nw = QuadTree(Rect(self.boundary.xmin, y_mid, x_mid, self.boundary.ymax), self.capacity, self.depth+1, self.max_depth)\n",
    "        self.ne = QuadTree(Rect(x_mid, y_mid, self.boundary.xmax, self.boundary.ymax), self.capacity, self.depth+1, self.max_depth)\n",
    "        self.sw = QuadTree(Rect(self.boundary.xmin, self.boundary.ymin, x_mid, y_mid), self.capacity, self.depth+1, self.max_depth)\n",
    "        self.se = QuadTree(Rect(x_mid, self.boundary.ymin, self.boundary.xmax, y_mid), self.capacity, self.depth+1, self.max_depth)\n",
    "        self.divided = True\n",
    "\n",
    "    def insert(self, geometry, data):\n",
    "        # Get bounding box of the geometry\n",
    "        minx, miny, maxx, maxy = geometry.bounds\n",
    "        item_bbox = Rect(minx, miny, maxx, maxy)\n",
    "\n",
    "        # If not in boundary, ignore\n",
    "        if not self.boundary.intersects(item_bbox):\n",
    "            return False\n",
    "\n",
    "        # MX-CIF Style: If object fits into a child, push it down.\n",
    "        # Otherwise (overlaps split lines), keep it here.\n",
    "        \n",
    "        if self.divided:\n",
    "            if self.nw.boundary.contains_rect(item_bbox):\n",
    "                return self.nw.insert(geometry, data)\n",
    "            elif self.ne.boundary.contains_rect(item_bbox):\n",
    "                return self.ne.insert(geometry, data)\n",
    "            elif self.sw.boundary.contains_rect(item_bbox):\n",
    "                return self.sw.insert(geometry, data)\n",
    "            elif self.se.boundary.contains_rect(item_bbox):\n",
    "                return self.se.insert(geometry, data)\n",
    "            # If it doesn't fit strictly in any child, it stays here (or if it's a point on the edge)\n",
    "        \n",
    "        # Add to this node\n",
    "        self.objects.append((geometry, data))\n",
    "        \n",
    "        # Check capacity and split if needed (only if not at max depth)\n",
    "        if len(self.objects) > self.capacity and self.depth < self.max_depth:\n",
    "            if not self.divided:\n",
    "                self.subdivide()\n",
    "                # Re-distribute existing objects\n",
    "                # Note: In MX-CIF, we only push down objects that strictly fit.\n",
    "                # Objects that were already here might now fit into children.\n",
    "                new_objects = []\n",
    "                for geo, d in self.objects:\n",
    "                    b_minx, b_miny, b_maxx, b_maxy = geo.bounds\n",
    "                    b_rect = Rect(b_minx, b_miny, b_maxx, b_maxy)\n",
    "                    \n",
    "                    inserted = False\n",
    "                    if self.nw.boundary.contains_rect(b_rect):\n",
    "                        inserted = self.nw.insert(geo, d)\n",
    "                    elif self.ne.boundary.contains_rect(b_rect):\n",
    "                        inserted = self.ne.insert(geo, d)\n",
    "                    elif self.sw.boundary.contains_rect(b_rect):\n",
    "                        inserted = self.sw.insert(geo, d)\n",
    "                    elif self.se.boundary.contains_rect(b_rect):\n",
    "                        inserted = self.se.insert(geo, d)\n",
    "                    \n",
    "                    if not inserted:\n",
    "                        new_objects.append((geo, d))\n",
    "                \n",
    "                self.objects = new_objects\n",
    "                \n",
    "        return True\n",
    "\n",
    "    def query(self, range_rect, found_items=None):\n",
    "        if found_items is None:\n",
    "            found_items = []\n",
    "            \n",
    "        if not self.boundary.intersects(range_rect):\n",
    "            return found_items\n",
    "\n",
    "        # Check objects in this node\n",
    "        for geo, data in self.objects:\n",
    "            minx, miny, maxx, maxy = geo.bounds\n",
    "            obj_rect = Rect(minx, miny, maxx, maxy)\n",
    "            if range_rect.intersects(obj_rect):\n",
    "                found_items.append((geo, data))\n",
    "\n",
    "        # Recurse\n",
    "        if self.divided:\n",
    "            self.nw.query(range_rect, found_items)\n",
    "            self.ne.query(range_rect, found_items)\n",
    "            self.sw.query(range_rect, found_items)\n",
    "            self.se.query(range_rect, found_items)\n",
    "            \n",
    "        return found_items\n",
    "\n",
    "print(\"QuadTree class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "df173856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building QuadTree for Legless Lizards...\n",
      "Building QuadTree for Wetlands...\n",
      "Trees built successfully.\n",
      "Building QuadTree for Wetlands...\n",
      "Trees built successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Build QuadTrees for Datasets ---\n",
    "\n",
    "# Helper to get total bounds for the root node\n",
    "def get_total_bounds(gdf):\n",
    "    minx, miny, maxx, maxy = gdf.total_bounds\n",
    "    # Add a small buffer to avoid edge cases\n",
    "    return Rect(minx - 1, miny - 1, maxx + 1, maxy + 1)\n",
    "\n",
    "# 1. Build Lizard Tree (Points)\n",
    "print(\"Building QuadTree for Legless Lizards...\")\n",
    "lizard_bounds = get_total_bounds(legless_gdf)\n",
    "lizard_tree = QuadTree(lizard_bounds, capacity=20)\n",
    "for idx, row in legless_gdf.iterrows():\n",
    "    lizard_tree.insert(row.geometry, idx)\n",
    "\n",
    "# 2. Build Wetland Tree (Polygons)\n",
    "print(\"Building QuadTree for Wetlands...\")\n",
    "wetland_bounds = get_total_bounds(wetlands_gdf)\n",
    "wetland_tree = QuadTree(wetland_bounds, capacity=20)\n",
    "for idx, row in wetlands_gdf.iterrows():\n",
    "    wetland_tree.insert(row.geometry, row) # Storing the whole row as data for easy access\n",
    "\n",
    "print(\"Trees built successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "595dfd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query 1 (QuadTree) ---\n",
      "Removed 18 duplicate sightings.\n",
      "Final Count (Legless Lizards in Pine Ridge): 14\n",
      "Results saved to Results/QuadTree/Query1_Lizards_in_PineRidge.csv\n",
      "\n",
      "--- Query 2 (QuadTree) ---\n",
      "Removed 5 duplicate wetlands.\n",
      "Found 11 unique wetlands inside State/National Parks.\n",
      "Results saved to Results/QuadTree/Query2_Wetlands_in_Parks.csv\n",
      "\n",
      "--- Query 3 (QuadTree - Nearest Neighbor) ---\n",
      "Processing 29656 platypus sightings against 335 wetlands.\n",
      "CRS Info: Platypus=EPSG:3577, Wetlands=EPSG:3577\n",
      "Removed 5 duplicate wetlands.\n",
      "Found 11 unique wetlands inside State/National Parks.\n",
      "Results saved to Results/QuadTree/Query2_Wetlands_in_Parks.csv\n",
      "\n",
      "--- Query 3 (QuadTree - Nearest Neighbor) ---\n",
      "Processing 29656 platypus sightings against 335 wetlands.\n",
      "CRS Info: Platypus=EPSG:3577, Wetlands=EPSG:3577\n",
      "Removed 6260 duplicate platypus sightings.\n",
      "   Platypus_ID   Latitude   Longitude       Nearest_Wetland  Distance (m)\n",
      "0            0 -34.283333  119.450000  Muncoonie Lakes Area  2.083351e+06\n",
      "1            1 -38.155730  144.293950           Bulloo Lake  1.032990e+06\n",
      "2            2 -38.150160  144.301090           Bulloo Lake  1.032487e+06\n",
      "3            3 -38.082467  144.281096           Bulloo Lake  1.024839e+06\n",
      "4            4 -38.147793  144.311988           Bulloo Lake  1.032387e+06\n",
      "Processed 23396 unique platypus sightings.\n",
      "Results saved to Results/QuadTree/Query3_Platypus_Nearest_Wetland.csv\n",
      "Removed 6260 duplicate platypus sightings.\n",
      "   Platypus_ID   Latitude   Longitude       Nearest_Wetland  Distance (m)\n",
      "0            0 -34.283333  119.450000  Muncoonie Lakes Area  2.083351e+06\n",
      "1            1 -38.155730  144.293950           Bulloo Lake  1.032990e+06\n",
      "2            2 -38.150160  144.301090           Bulloo Lake  1.032487e+06\n",
      "3            3 -38.082467  144.281096           Bulloo Lake  1.024839e+06\n",
      "4            4 -38.147793  144.311988           Bulloo Lake  1.032387e+06\n",
      "Processed 23396 unique platypus sightings.\n",
      "Results saved to Results/QuadTree/Query3_Platypus_Nearest_Wetland.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Execute Queries using QuadTree ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = 'Results/QuadTree'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def run_query_1(lizard_tree, legless_gdf, protected_areas_gdf):\n",
    "    print(\"\\n--- Query 1 (QuadTree) ---\")\n",
    "    target_park_name = 'Pine Ridge Conservation Park'\n",
    "    pine_ridge_parts = protected_areas_gdf[protected_areas_gdf['estatename'] == target_park_name]\n",
    "\n",
    "    lizards_found = []\n",
    "    \n",
    "    # Check CRS consistency\n",
    "    source_crs = protected_areas_gdf.crs\n",
    "    target_crs = legless_gdf.crs\n",
    "    \n",
    "    if source_crs != target_crs:\n",
    "        print(f\"Notice: CRS mismatch detected. Reprojecting query geometry from {source_crs} to {target_crs}.\")\n",
    "\n",
    "    for idx, park_part in pine_ridge_parts.iterrows():\n",
    "        geom = park_part.geometry\n",
    "        if source_crs != target_crs:\n",
    "            geom = gpd.GeoSeries([geom], crs=source_crs).to_crs(target_crs).iloc[0]\n",
    "\n",
    "        pr_minx, pr_miny, pr_maxx, pr_maxy = geom.bounds\n",
    "        search_rect = Rect(pr_minx, pr_miny, pr_maxx, pr_maxy)\n",
    "\n",
    "        candidates = lizard_tree.query(search_rect)\n",
    "        \n",
    "        for geo, lizard_idx in candidates:\n",
    "            if geom.contains(geo):\n",
    "                row = legless_gdf.loc[lizard_idx]\n",
    "                lizards_found.append({\n",
    "                    'Latitude': row['Latitude'],\n",
    "                    'Longitude': row['Longitude']\n",
    "                })\n",
    "\n",
    "    df_q1 = pd.DataFrame(lizards_found)\n",
    "    if not df_q1.empty:\n",
    "        initial_count = len(df_q1)\n",
    "        df_q1 = df_q1.drop_duplicates(subset=['Latitude', 'Longitude'])\n",
    "        final_count = len(df_q1)\n",
    "        \n",
    "        if initial_count > final_count:\n",
    "            print(f\"Removed {initial_count - final_count} duplicate sightings.\")\n",
    "            \n",
    "        print(f\"Final Count (Legless Lizards in Pine Ridge): {final_count}\")\n",
    "        \n",
    "        output_file = os.path.join(output_dir, 'Query1_Lizards_in_PineRidge.csv')\n",
    "        df_q1.to_csv(output_file, index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"Final Count: 0\")\n",
    "\n",
    "def run_query_2(wetland_tree, wetlands_gdf, protected_areas_gdf):\n",
    "    print(\"\\n--- Query 2 (QuadTree) ---\")\n",
    "    target_parks = protected_areas_gdf[protected_areas_gdf['dcdbtenure'].isin(['State Forest', 'National Park'])]\n",
    "    wetlands_inside_data = []\n",
    "\n",
    "    source_crs_q2 = protected_areas_gdf.crs\n",
    "    target_crs_q2 = wetlands_gdf.crs \n",
    "\n",
    "    for idx, park in target_parks.iterrows():\n",
    "        geom = park.geometry\n",
    "        if source_crs_q2 != target_crs_q2:\n",
    "            geom = gpd.GeoSeries([geom], crs=source_crs_q2).to_crs(target_crs_q2).iloc[0]\n",
    "\n",
    "        p_minx, p_miny, p_maxx, p_maxy = geom.bounds\n",
    "        search_rect = Rect(p_minx, p_miny, p_maxx, p_maxy)\n",
    "        \n",
    "        candidates = wetland_tree.query(search_rect)\n",
    "        \n",
    "        for wet_geo, wet_data in candidates:\n",
    "            if geom.contains(wet_geo):\n",
    "                wetlands_inside_data.append({\n",
    "                    'wname': wet_data['wname'],\n",
    "                    'estatename': park['estatename'],\n",
    "                    'dcdbtenure': park['dcdbtenure']\n",
    "                })\n",
    "\n",
    "    df_q2 = pd.DataFrame(wetlands_inside_data)\n",
    "    if not df_q2.empty:\n",
    "        initial_count = len(df_q2)\n",
    "        df_q2 = df_q2.drop_duplicates(subset=['wname'])\n",
    "        final_count = len(df_q2)\n",
    "        \n",
    "        if initial_count > final_count:\n",
    "            print(f\"Removed {initial_count - final_count} duplicate wetlands.\")\n",
    "            \n",
    "        print(f\"Found {final_count} unique wetlands inside State/National Parks.\")\n",
    "        \n",
    "        output_file = os.path.join(output_dir, 'Query2_Wetlands_in_Parks.csv')\n",
    "        df_q2.to_csv(output_file, index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"Found 0 wetlands.\")\n",
    "\n",
    "def run_query_3(wetland_tree, wetlands_gdf, platypus_gdf):\n",
    "    print(\"\\n--- Query 3 (QuadTree - Nearest Neighbor) ---\")\n",
    "    print(f\"Processing {len(platypus_gdf)} platypus sightings against {len(wetlands_gdf)} wetlands.\")\n",
    "    \n",
    "    results_q3 = []\n",
    "\n",
    "    source_crs_q3 = platypus_gdf.crs\n",
    "    target_crs_q3 = wetlands_gdf.crs\n",
    "    \n",
    "    print(f\"CRS Info: Platypus={source_crs_q3}, Wetlands={target_crs_q3}\")\n",
    "\n",
    "    # --- Safety Check for CRS Mismatch ---\n",
    "    tree_xmin = wetland_tree.boundary.xmin\n",
    "    if tree_xmin < 180 and target_crs_q3 and not target_crs_q3.is_geographic:\n",
    "        print(\"WARNING: QuadTree seems to contain Geographic coordinates (Lat/Lon), but 'wetlands_gdf' is Projected.\")\n",
    "        print(\"SUGGESTION: Please re-run the 'Build QuadTrees' cell to update the tree with the reprojected data.\")\n",
    "        return \n",
    "\n",
    "    is_geographic = False\n",
    "    if target_crs_q3 and hasattr(target_crs_q3, 'is_geographic'):\n",
    "        is_geographic = target_crs_q3.is_geographic\n",
    "    \n",
    "    metric_crs = \"EPSG:3577\" \n",
    "\n",
    "    if is_geographic:\n",
    "        print(\"Notice: Data is in Geographic CRS (Degrees). Distances will be converted to Meters using EPSG:3577.\")\n",
    "\n",
    "    # Define max radius to cover the entire region (e.g., Australia)\n",
    "    # 60 degrees or 6,000,000 meters (6000km) should cover everything\n",
    "    MAX_RADIUS_LIMIT = 60.0 if is_geographic else 6000000.0\n",
    "\n",
    "    for idx, platypus in platypus_gdf.iterrows():\n",
    "        p_point = platypus.geometry\n",
    "        \n",
    "        if source_crs_q3 != target_crs_q3:\n",
    "            p_point = gpd.GeoSeries([p_point], crs=source_crs_q3).to_crs(target_crs_q3).iloc[0]\n",
    "\n",
    "        px, py = p_point.x, p_point.y\n",
    "        \n",
    "        # Start with a reasonable radius\n",
    "        radius = 0.1 if is_geographic else 10000.0 # Start at ~10km\n",
    "        found_nearest = False\n",
    "        min_dist = float('inf')\n",
    "        nearest_wetland_name = None\n",
    "        nearest_wetland_geo = None\n",
    "        \n",
    "        while not found_nearest and radius <= MAX_RADIUS_LIMIT:\n",
    "            search_rect = Rect(px - radius, py - radius, px + radius, py + radius)\n",
    "            candidates = wetland_tree.query(search_rect)\n",
    "            \n",
    "            if candidates:\n",
    "                for wet_geo, wet_data in candidates:\n",
    "                    dist = p_point.distance(wet_geo)\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        nearest_wetland_name = wet_data['wname']\n",
    "                        nearest_wetland_geo = wet_geo\n",
    "                \n",
    "                # If we found a candidate within the current search radius, we can stop.\n",
    "                if min_dist < radius:\n",
    "                    found_nearest = True\n",
    "                else:\n",
    "                    radius *= 2 \n",
    "            else:\n",
    "                radius *= 2 \n",
    "                \n",
    "        final_distance = min_dist\n",
    "        if is_geographic and nearest_wetland_geo is not None:\n",
    "            p_series = gpd.GeoSeries([p_point], crs=target_crs_q3).to_crs(metric_crs)\n",
    "            w_series = gpd.GeoSeries([nearest_wetland_geo], crs=target_crs_q3).to_crs(metric_crs)\n",
    "            final_distance = p_series.distance(w_series).iloc[0]\n",
    "        elif min_dist == float('inf'):\n",
    "            final_distance = None\n",
    "\n",
    "        results_q3.append({\n",
    "            'Platypus_ID': idx,\n",
    "            'Latitude': platypus['Latitude'],\n",
    "            'Longitude': platypus['Longitude'],\n",
    "            'Nearest_Wetland': nearest_wetland_name,\n",
    "            'Distance (m)': final_distance\n",
    "        })\n",
    "\n",
    "    df_q3 = pd.DataFrame(results_q3)\n",
    "\n",
    "    initial_count = len(df_q3)\n",
    "    df_q3 = df_q3.drop_duplicates(subset=['Latitude', 'Longitude'])\n",
    "    final_count = len(df_q3)\n",
    "\n",
    "    if initial_count > final_count:\n",
    "        print(f\"Removed {initial_count - final_count} duplicate platypus sightings.\")\n",
    "\n",
    "    print(df_q3.head())\n",
    "    print(f\"Processed {final_count} unique platypus sightings.\")\n",
    "\n",
    "    output_file = os.path.join(output_dir, 'Query3_Platypus_Nearest_Wetland.csv')\n",
    "    df_q3.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Execute\n",
    "# Ensure global variables are available\n",
    "if 'lizard_tree' in globals() and 'wetland_tree' in globals():\n",
    "    run_query_1(lizard_tree, legless_gdf, protected_areas_gdf)\n",
    "    run_query_2(wetland_tree, wetlands_gdf, protected_areas_gdf)\n",
    "    run_query_3(wetland_tree, wetlands_gdf, platypus_gdf)\n",
    "else:\n",
    "    print(\"Error: QuadTrees not found. Please run the 'Build QuadTrees' cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "76328338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTree class defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Custom R-Tree Implementation ---\n",
    "\n",
    "class RTreeNode:\n",
    "    def __init__(self, is_leaf=True, capacity=4):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.capacity = capacity\n",
    "        self.children = []  # List of (bbox, child_node_or_data)\n",
    "        self.bbox = None    # Bounding box of this node\n",
    "\n",
    "    def update_bbox(self):\n",
    "        if not self.children:\n",
    "            self.bbox = None\n",
    "            return\n",
    "\n",
    "        minx = min(child[0][0] for child in self.children)\n",
    "        miny = min(child[0][1] for child in self.children)\n",
    "        maxx = max(child[0][2] for child in self.children)\n",
    "        maxy = max(child[0][3] for child in self.children)\n",
    "        self.bbox = (minx, miny, maxx, maxy)\n",
    "\n",
    "    def insert(self, item_bbox, item_data):\n",
    "        if self.is_leaf:\n",
    "            self.children.append((item_bbox, item_data))\n",
    "            self.update_bbox()\n",
    "            if len(self.children) > self.capacity:\n",
    "                return self.split()\n",
    "            return None\n",
    "        else:\n",
    "            # Choose best child to insert into (least enlargement)\n",
    "            best_child_idx = self._choose_subtree(item_bbox)\n",
    "            new_child = self.children[best_child_idx][1].insert(item_bbox, item_data)\n",
    "            \n",
    "            if new_child:\n",
    "                self.children.append(new_child)\n",
    "                if len(self.children) > self.capacity:\n",
    "                    split_result = self.split()\n",
    "                    self.update_bbox() # Update after split\n",
    "                    return split_result\n",
    "            \n",
    "            # Update bbox of the chosen child in the children list\n",
    "            child_node = self.children[best_child_idx][1]\n",
    "            self.children[best_child_idx] = (child_node.bbox, child_node)\n",
    "            self.update_bbox()\n",
    "            return None\n",
    "\n",
    "    def _choose_subtree(self, item_bbox):\n",
    "        best_idx = -1\n",
    "        min_enlargement = float('inf')\n",
    "        \n",
    "        for i, (child_bbox, _) in enumerate(self.children):\n",
    "            # Calculate enlargement\n",
    "            enlarged_bbox = (\n",
    "                min(child_bbox[0], item_bbox[0]),\n",
    "                min(child_bbox[1], item_bbox[1]),\n",
    "                max(child_bbox[2], item_bbox[2]),\n",
    "                max(child_bbox[3], item_bbox[3])\n",
    "            )\n",
    "            current_area = (child_bbox[2] - child_bbox[0]) * (child_bbox[3] - child_bbox[1])\n",
    "            new_area = (enlarged_bbox[2] - enlarged_bbox[0]) * (enlarged_bbox[3] - enlarged_bbox[1])\n",
    "            enlargement = new_area - current_area\n",
    "            \n",
    "            if enlargement < min_enlargement:\n",
    "                min_enlargement = enlargement\n",
    "                best_idx = i\n",
    "        return best_idx\n",
    "\n",
    "    def split(self):\n",
    "        # Linear Split Strategy (Simplified)\n",
    "        # Sort by x-min and split in half\n",
    "        self.children.sort(key=lambda x: x[0][0])\n",
    "        mid = len(self.children) // 2\n",
    "        \n",
    "        new_node = RTreeNode(is_leaf=self.is_leaf, capacity=self.capacity)\n",
    "        new_node.children = self.children[mid:]\n",
    "        self.children = self.children[:mid]\n",
    "        \n",
    "        self.update_bbox()\n",
    "        new_node.update_bbox()\n",
    "        \n",
    "        return (new_node.bbox, new_node)\n",
    "\n",
    "    def query(self, search_bbox, results=None):\n",
    "        if results is None:\n",
    "            results = []\n",
    "            \n",
    "        if not self.bbox or not self._intersects(self.bbox, search_bbox):\n",
    "            return results\n",
    "\n",
    "        if self.is_leaf:\n",
    "            for item_bbox, item_data in self.children:\n",
    "                if self._intersects(item_bbox, search_bbox):\n",
    "                    results.append((item_bbox, item_data))\n",
    "        else:\n",
    "            for child_bbox, child_node in self.children:\n",
    "                if self._intersects(child_bbox, search_bbox):\n",
    "                    child_node.query(search_bbox, results)\n",
    "        return results\n",
    "\n",
    "    def _intersects(self, box1, box2):\n",
    "        return not (box1[2] < box2[0] or box1[0] > box2[2] or\n",
    "                    box1[3] < box2[1] or box1[1] > box2[3])\n",
    "\n",
    "class RTree:\n",
    "    def __init__(self, capacity=4):\n",
    "        self.root = RTreeNode(is_leaf=True, capacity=capacity)\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def insert(self, geometry, data):\n",
    "        minx, miny, maxx, maxy = geometry.bounds\n",
    "        item_bbox = (minx, miny, maxx, maxy)\n",
    "        \n",
    "        new_child = self.root.insert(item_bbox, data)\n",
    "        if new_child:\n",
    "            # Root split, create new root\n",
    "            new_root = RTreeNode(is_leaf=False, capacity=self.capacity)\n",
    "            new_root.children.append((self.root.bbox, self.root))\n",
    "            new_root.children.append(new_child)\n",
    "            new_root.update_bbox()\n",
    "            self.root = new_root\n",
    "\n",
    "    def query(self, search_bbox):\n",
    "        return self.root.query(search_bbox)\n",
    "\n",
    "print(\"RTree class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "92c3968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building R-Tree for Legless Lizards...\n",
      "Building R-Tree for Wetlands...\n",
      "R-Trees built successfully.\n",
      "Building R-Tree for Wetlands...\n",
      "R-Trees built successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Build R-Trees for Datasets ---\n",
    "\n",
    "# 1. Build Lizard R-Tree\n",
    "print(\"Building R-Tree for Legless Lizards...\")\n",
    "lizard_rtree = RTree(capacity=10)\n",
    "for idx, row in legless_gdf.iterrows():\n",
    "    lizard_rtree.insert(row.geometry, idx)\n",
    "\n",
    "# 2. Build Wetland R-Tree\n",
    "print(\"Building R-Tree for Wetlands...\")\n",
    "wetland_rtree = RTree(capacity=10)\n",
    "for idx, row in wetlands_gdf.iterrows():\n",
    "    wetland_rtree.insert(row.geometry, row)\n",
    "\n",
    "print(\"R-Trees built successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a917f260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query 1 (R-Tree) ---\n",
      "Removed 18 duplicate sightings.\n",
      "Final Count (Legless Lizards in Pine Ridge): 14\n",
      "Results saved to Results/R-Tree/Query1_Lizards_in_PineRidge.csv\n",
      "\n",
      "--- Query 2 (R-Tree) ---\n",
      "Removed 5 duplicate wetlands.\n",
      "Found 11 unique wetlands inside State/National Parks.\n",
      "Results saved to Results/R-Tree/Query2_Wetlands_in_Parks.csv\n",
      "\n",
      "--- Query 3 (R-Tree - Nearest Neighbor) ---\n",
      "Processing 29656 platypus sightings against 335 wetlands.\n",
      "Removed 6260 duplicate platypus sightings.\n",
      "   Platypus_ID   Latitude   Longitude       Nearest_Wetland  Distance (m)\n",
      "0            0 -34.283333  119.450000  Muncoonie Lakes Area  2.083351e+06\n",
      "1            1 -38.155730  144.293950           Bulloo Lake  1.032990e+06\n",
      "2            2 -38.150160  144.301090           Bulloo Lake  1.032487e+06\n",
      "3            3 -38.082467  144.281096           Bulloo Lake  1.024839e+06\n",
      "4            4 -38.147793  144.311988           Bulloo Lake  1.032387e+06\n",
      "Processed 23396 unique platypus sightings.\n",
      "Results saved to Results/R-Tree/Query3_Platypus_Nearest_Wetland.csv\n",
      "Removed 6260 duplicate platypus sightings.\n",
      "   Platypus_ID   Latitude   Longitude       Nearest_Wetland  Distance (m)\n",
      "0            0 -34.283333  119.450000  Muncoonie Lakes Area  2.083351e+06\n",
      "1            1 -38.155730  144.293950           Bulloo Lake  1.032990e+06\n",
      "2            2 -38.150160  144.301090           Bulloo Lake  1.032487e+06\n",
      "3            3 -38.082467  144.281096           Bulloo Lake  1.024839e+06\n",
      "4            4 -38.147793  144.311988           Bulloo Lake  1.032387e+06\n",
      "Processed 23396 unique platypus sightings.\n",
      "Results saved to Results/R-Tree/Query3_Platypus_Nearest_Wetland.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Execute Queries using R-Tree ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = 'Results/R-Tree'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def run_query_1_rtree(lizard_rtree, legless_gdf, protected_areas_gdf):\n",
    "    print(\"\\n--- Query 1 (R-Tree) ---\")\n",
    "    target_park_name = 'Pine Ridge Conservation Park'\n",
    "    pine_ridge_parts = protected_areas_gdf[protected_areas_gdf['estatename'] == target_park_name]\n",
    "\n",
    "    lizards_found = []\n",
    "    \n",
    "    # Check CRS consistency\n",
    "    source_crs = protected_areas_gdf.crs\n",
    "    target_crs = legless_gdf.crs\n",
    "    \n",
    "    if source_crs != target_crs:\n",
    "        print(f\"Notice: CRS mismatch detected. Reprojecting query geometry from {source_crs} to {target_crs}.\")\n",
    "\n",
    "    for idx, park_part in pine_ridge_parts.iterrows():\n",
    "        geom = park_part.geometry\n",
    "        if source_crs != target_crs:\n",
    "            geom = gpd.GeoSeries([geom], crs=source_crs).to_crs(target_crs).iloc[0]\n",
    "\n",
    "        pr_minx, pr_miny, pr_maxx, pr_maxy = geom.bounds\n",
    "        search_bbox = (pr_minx, pr_miny, pr_maxx, pr_maxy)\n",
    "\n",
    "        # 1. Filter candidates using R-Tree\n",
    "        candidates = lizard_rtree.query(search_bbox)\n",
    "        \n",
    "        # 2. Refine using exact geometry check\n",
    "        for bbox, lizard_idx in candidates:\n",
    "            # Retrieve geometry from original GDF using index\n",
    "            geo = legless_gdf.loc[lizard_idx].geometry\n",
    "            if geom.contains(geo):\n",
    "                row = legless_gdf.loc[lizard_idx]\n",
    "                lizards_found.append({\n",
    "                    'Latitude': row['Latitude'],\n",
    "                    'Longitude': row['Longitude']\n",
    "                })\n",
    "\n",
    "    df_q1 = pd.DataFrame(lizards_found)\n",
    "    if not df_q1.empty:\n",
    "        initial_count = len(df_q1)\n",
    "        df_q1 = df_q1.drop_duplicates(subset=['Latitude', 'Longitude'])\n",
    "        final_count = len(df_q1)\n",
    "        \n",
    "        if initial_count > final_count:\n",
    "            print(f\"Removed {initial_count - final_count} duplicate sightings.\")\n",
    "            \n",
    "        print(f\"Final Count (Legless Lizards in Pine Ridge): {final_count}\")\n",
    "        \n",
    "        output_file = os.path.join(output_dir, 'Query1_Lizards_in_PineRidge.csv')\n",
    "        df_q1.to_csv(output_file, index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"Final Count: 0\")\n",
    "\n",
    "def run_query_2_rtree(wetland_rtree, wetlands_gdf, protected_areas_gdf):\n",
    "    print(\"\\n--- Query 2 (R-Tree) ---\")\n",
    "    target_parks = protected_areas_gdf[protected_areas_gdf['dcdbtenure'].isin(['State Forest', 'National Park'])]\n",
    "    wetlands_inside_data = []\n",
    "\n",
    "    source_crs_q2 = protected_areas_gdf.crs\n",
    "    target_crs_q2 = wetlands_gdf.crs \n",
    "\n",
    "    for idx, park in target_parks.iterrows():\n",
    "        geom = park.geometry\n",
    "        if source_crs_q2 != target_crs_q2:\n",
    "            geom = gpd.GeoSeries([geom], crs=source_crs_q2).to_crs(target_crs_q2).iloc[0]\n",
    "\n",
    "        p_minx, p_miny, p_maxx, p_maxy = geom.bounds\n",
    "        search_bbox = (p_minx, p_miny, p_maxx, p_maxy)\n",
    "        \n",
    "        # 1. Filter candidates\n",
    "        candidates = wetland_rtree.query(search_bbox)\n",
    "        \n",
    "        # 2. Refine\n",
    "        for wet_bbox, wet_data in candidates:\n",
    "            wet_geo = wet_data.geometry\n",
    "            if geom.contains(wet_geo):\n",
    "                wetlands_inside_data.append({\n",
    "                    'wname': wet_data['wname'],\n",
    "                    'estatename': park['estatename'],\n",
    "                    'dcdbtenure': park['dcdbtenure']\n",
    "                })\n",
    "\n",
    "    df_q2 = pd.DataFrame(wetlands_inside_data)\n",
    "    if not df_q2.empty:\n",
    "        initial_count = len(df_q2)\n",
    "        df_q2 = df_q2.drop_duplicates(subset=['wname'])\n",
    "        final_count = len(df_q2)\n",
    "        \n",
    "        if initial_count > final_count:\n",
    "            print(f\"Removed {initial_count - final_count} duplicate wetlands.\")\n",
    "            \n",
    "        print(f\"Found {final_count} unique wetlands inside State/National Parks.\")\n",
    "        \n",
    "        output_file = os.path.join(output_dir, 'Query2_Wetlands_in_Parks.csv')\n",
    "        df_q2.to_csv(output_file, index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"Found 0 wetlands.\")\n",
    "\n",
    "def run_query_3_rtree(wetland_rtree, wetlands_gdf, platypus_gdf):\n",
    "    print(\"\\n--- Query 3 (R-Tree - Nearest Neighbor) ---\")\n",
    "    print(f\"Processing {len(platypus_gdf)} platypus sightings against {len(wetlands_gdf)} wetlands.\")\n",
    "    \n",
    "    results_q3 = []\n",
    "\n",
    "    source_crs_q3 = platypus_gdf.crs\n",
    "    target_crs_q3 = wetlands_gdf.crs\n",
    "    \n",
    "    # --- Safety Check for CRS Mismatch ---\n",
    "    is_geographic = False\n",
    "    if target_crs_q3 and hasattr(target_crs_q3, 'is_geographic'):\n",
    "        is_geographic = target_crs_q3.is_geographic\n",
    "    \n",
    "    metric_crs = \"EPSG:3577\" \n",
    "    MAX_RADIUS_LIMIT = 60.0 if is_geographic else 6000000.0\n",
    "\n",
    "    for idx, platypus in platypus_gdf.iterrows():\n",
    "        p_point = platypus.geometry\n",
    "        \n",
    "        if source_crs_q3 != target_crs_q3:\n",
    "            p_point = gpd.GeoSeries([p_point], crs=source_crs_q3).to_crs(target_crs_q3).iloc[0]\n",
    "\n",
    "        px, py = p_point.x, p_point.y\n",
    "        \n",
    "        # Iterative search: Start small, expand if needed\n",
    "        radius = 0.1 if is_geographic else 10000.0\n",
    "        found_nearest = False\n",
    "        min_dist = float('inf')\n",
    "        nearest_wetland_name = None\n",
    "        nearest_wetland_geo = None\n",
    "        \n",
    "        while not found_nearest and radius <= MAX_RADIUS_LIMIT:\n",
    "            search_bbox = (px - radius, py - radius, px + radius, py + radius)\n",
    "            candidates = wetland_rtree.query(search_bbox)\n",
    "            \n",
    "            if candidates:\n",
    "                for wet_bbox, wet_data in candidates:\n",
    "                    wet_geo = wet_data.geometry\n",
    "                    dist = p_point.distance(wet_geo)\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        nearest_wetland_name = wet_data['wname']\n",
    "                        nearest_wetland_geo = wet_geo\n",
    "                \n",
    "                if min_dist < radius:\n",
    "                    found_nearest = True\n",
    "                else:\n",
    "                    radius *= 2\n",
    "            else:\n",
    "                radius *= 2\n",
    "        \n",
    "        final_distance = min_dist\n",
    "        if is_geographic and nearest_wetland_geo is not None:\n",
    "            p_series = gpd.GeoSeries([p_point], crs=target_crs_q3).to_crs(metric_crs)\n",
    "            w_series = gpd.GeoSeries([nearest_wetland_geo], crs=target_crs_q3).to_crs(metric_crs)\n",
    "            final_distance = p_series.distance(w_series).iloc[0]\n",
    "        elif min_dist == float('inf'):\n",
    "            final_distance = None\n",
    "            \n",
    "        results_q3.append({\n",
    "            'Platypus_ID': idx,\n",
    "            'Latitude': platypus['Latitude'],\n",
    "            'Longitude': platypus['Longitude'],\n",
    "            'Nearest_Wetland': nearest_wetland_name,\n",
    "            'Distance (m)': final_distance\n",
    "        })\n",
    "\n",
    "    df_q3 = pd.DataFrame(results_q3)\n",
    "    \n",
    "    initial_count = len(df_q3)\n",
    "    df_q3 = df_q3.drop_duplicates(subset=['Latitude', 'Longitude'])\n",
    "    final_count = len(df_q3)\n",
    "\n",
    "    if initial_count > final_count:\n",
    "        print(f\"Removed {initial_count - final_count} duplicate platypus sightings.\")\n",
    "\n",
    "    print(df_q3.head())\n",
    "    print(f\"Processed {final_count} unique platypus sightings.\")\n",
    "    \n",
    "    output_file = os.path.join(output_dir, 'Query3_Platypus_Nearest_Wetland.csv')\n",
    "    df_q3.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Execute\n",
    "if 'lizard_rtree' in globals() and 'wetland_rtree' in globals():\n",
    "    run_query_1_rtree(lizard_rtree, legless_gdf, protected_areas_gdf)\n",
    "    run_query_2_rtree(wetland_rtree, wetlands_gdf, protected_areas_gdf)\n",
    "    run_query_3_rtree(wetland_rtree, wetlands_gdf, platypus_gdf)\n",
    "else:\n",
    "    print(\"Error: R-Trees not found. Please run the 'Build R-Trees' cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9dae5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packed R-Tree builder defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Z-Order (Morton Code) Helper & Packed R-Tree Builder ---\n",
    "\n",
    "class ZOrderCurve:\n",
    "    def __init__(self, bounds):\n",
    "        self.minx, self.miny, self.maxx, self.maxy = bounds\n",
    "        # Avoid division by zero\n",
    "        width = self.maxx - self.minx\n",
    "        height = self.maxy - self.miny\n",
    "        self.scale_x = (2**30 - 1) / width if width > 0 else 0\n",
    "        self.scale_y = (2**30 - 1) / height if height > 0 else 0\n",
    "\n",
    "    def get_z(self, x, y):\n",
    "        # Normalize to integer space\n",
    "        xi = int((x - self.minx) * self.scale_x)\n",
    "        yi = int((y - self.miny) * self.scale_y)\n",
    "        \n",
    "        # Interleave bits (Morton Code)\n",
    "        z = 0\n",
    "        for i in range(30):\n",
    "            z |= (xi & (1 << i)) << i | (yi & (1 << i)) << (i + 1)\n",
    "        return z\n",
    "\n",
    "def build_packed_rtree(gdf, capacity=10):\n",
    "    \"\"\"\n",
    "    Builds a Packed R-Tree using Z-Order sorting (STR-like but with Z-curve).\n",
    "    \"\"\"\n",
    "    # 1. Calculate Global Bounds for Z-Curve\n",
    "    total_bounds = gdf.total_bounds\n",
    "    z_curve = ZOrderCurve(total_bounds)\n",
    "    \n",
    "    # 2. Prepare items with Z-values\n",
    "    items = []\n",
    "    for idx, row in gdf.iterrows():\n",
    "        geo = row.geometry\n",
    "        # Use centroid for Z-value ordering\n",
    "        centroid = geo.centroid\n",
    "        z_val = z_curve.get_z(centroid.x, centroid.y)\n",
    "        items.append({\n",
    "            'z': z_val,\n",
    "            'bbox': geo.bounds,\n",
    "            'data': idx if 'geometry' in row else row, # Store index for points, row for polygons (consistent with previous logic)\n",
    "            'geometry': geo\n",
    "        })\n",
    "        \n",
    "    # 3. Sort by Z-value\n",
    "    items.sort(key=lambda x: x['z'])\n",
    "    \n",
    "    # 4. Build Leaf Layer\n",
    "    current_level_nodes = []\n",
    "    # Group items into leaf nodes\n",
    "    for i in range(0, len(items), capacity):\n",
    "        batch = items[i : i + capacity]\n",
    "        leaf_node = RTreeNode(is_leaf=True, capacity=capacity)\n",
    "        for item in batch:\n",
    "            # RTreeNode expects (bbox, data)\n",
    "            # For consistency with previous RTree, we store 'data' which is idx or row\n",
    "            # But wait, previous RTree stored (bbox, idx) for points and (bbox, row) for polygons\n",
    "            # Let's stick to that.\n",
    "            data_to_store = item['data']\n",
    "            # If it's a polygon row, we might need to access geometry later. \n",
    "            # The previous implementation stored 'row' for wetlands.\n",
    "            leaf_node.children.append((item['bbox'], data_to_store))\n",
    "        \n",
    "        leaf_node.update_bbox()\n",
    "        current_level_nodes.append(leaf_node)\n",
    "        \n",
    "    # 5. Build Internal Layers (Bottom-Up)\n",
    "    while len(current_level_nodes) > 1:\n",
    "        next_level_nodes = []\n",
    "        for i in range(0, len(current_level_nodes), capacity):\n",
    "            batch = current_level_nodes[i : i + capacity]\n",
    "            parent_node = RTreeNode(is_leaf=False, capacity=capacity)\n",
    "            for child in batch:\n",
    "                parent_node.children.append((child.bbox, child))\n",
    "            \n",
    "            parent_node.update_bbox()\n",
    "            next_level_nodes.append(parent_node)\n",
    "        current_level_nodes = next_level_nodes\n",
    "        \n",
    "    # 6. Return RTree instance\n",
    "    rtree = RTree(capacity=capacity)\n",
    "    if current_level_nodes:\n",
    "        rtree.root = current_level_nodes[0]\n",
    "    return rtree\n",
    "\n",
    "print(\"Packed R-Tree builder defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dd2e980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Packed R-Tree (Z-Order) for Legless Lizards...\n",
      "Building Packed R-Tree (Z-Order) for Wetlands...\n",
      "Packed R-Trees built successfully.\n",
      "Building Packed R-Tree (Z-Order) for Wetlands...\n",
      "Packed R-Trees built successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Build Packed R-Trees (Z-Order) ---\n",
    "\n",
    "# 1. Build Lizard Packed R-Tree\n",
    "print(\"Building Packed R-Tree (Z-Order) for Legless Lizards...\")\n",
    "# For lizards (points), we stored 'idx' as data in previous examples\n",
    "# We need to ensure build_packed_rtree handles this.\n",
    "# I modified build_packed_rtree to store 'idx' if it's a point dataset (logic inside: data=idx)\n",
    "lizard_z_rtree = build_packed_rtree(legless_gdf, capacity=10)\n",
    "\n",
    "# 2. Build Wetland Packed R-Tree\n",
    "print(\"Building Packed R-Tree (Z-Order) for Wetlands...\")\n",
    "# For wetlands (polygons), we stored 'row' as data\n",
    "# I need to adjust the call or the function to handle this specific data storage preference.\n",
    "# Actually, let's pass a flag or handle it inside.\n",
    "# In the function above: \"data\": idx if 'geometry' in row else row\n",
    "# Wait, row always has 'geometry'. \n",
    "# Let's refine the builder usage slightly to match previous logic exactly.\n",
    "\n",
    "# Redefine builder call for Wetlands to explicitly store the row\n",
    "def build_wetland_packed_rtree(gdf, capacity=10):\n",
    "    total_bounds = gdf.total_bounds\n",
    "    z_curve = ZOrderCurve(total_bounds)\n",
    "    items = []\n",
    "    for idx, row in gdf.iterrows():\n",
    "        geo = row.geometry\n",
    "        centroid = geo.centroid\n",
    "        z_val = z_curve.get_z(centroid.x, centroid.y)\n",
    "        items.append({\n",
    "            'z': z_val,\n",
    "            'bbox': geo.bounds,\n",
    "            'data': row, # Store WHOLE ROW\n",
    "            'geometry': geo\n",
    "        })\n",
    "    items.sort(key=lambda x: x['z'])\n",
    "    \n",
    "    current_level_nodes = []\n",
    "    for i in range(0, len(items), capacity):\n",
    "        batch = items[i : i + capacity]\n",
    "        leaf_node = RTreeNode(is_leaf=True, capacity=capacity)\n",
    "        for item in batch:\n",
    "            leaf_node.children.append((item['bbox'], item['data']))\n",
    "        leaf_node.update_bbox()\n",
    "        current_level_nodes.append(leaf_node)\n",
    "        \n",
    "    while len(current_level_nodes) > 1:\n",
    "        next_level_nodes = []\n",
    "        for i in range(0, len(current_level_nodes), capacity):\n",
    "            batch = current_level_nodes[i : i + capacity]\n",
    "            parent_node = RTreeNode(is_leaf=False, capacity=capacity)\n",
    "            for child in batch:\n",
    "                parent_node.children.append((child.bbox, child))\n",
    "            parent_node.update_bbox()\n",
    "            next_level_nodes.append(parent_node)\n",
    "        current_level_nodes = next_level_nodes\n",
    "        \n",
    "    rtree = RTree(capacity=capacity)\n",
    "    if current_level_nodes:\n",
    "        rtree.root = current_level_nodes[0]\n",
    "    return rtree\n",
    "\n",
    "wetland_z_rtree = build_wetland_packed_rtree(wetlands_gdf, capacity=10)\n",
    "\n",
    "print(\"Packed R-Trees built successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execute Queries using Packed R-Tree (Z-Order) ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = 'Results/Z-Order'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def run_query_1_packed(lizard_z_rtree, legless_gdf, protected_areas_gdf):\n",
    "    print(\"\\n--- Query 1 (Packed R-Tree) ---\")\n",
    "    target_park_name = 'Pine Ridge Conservation Park'\n",
    "    pine_ridge_parts = protected_areas_gdf[protected_areas_gdf['estatename'] == target_park_name]\n",
    "\n",
    "    lizards_found = []\n",
    "    \n",
    "    # Check CRS consistency\n",
    "    source_crs = protected_areas_gdf.crs\n",
    "    target_crs = legless_gdf.crs\n",
    "    \n",
    "    if source_crs != target_crs:\n",
    "        print(f\"Notice: CRS mismatch detected. Reprojecting query geometry from {source_crs} to {target_crs}.\")\n",
    "\n",
    "    for idx, park_part in pine_ridge_parts.iterrows():\n",
    "        geom = park_part.geometry\n",
    "        if source_crs != target_crs:\n",
    "            geom = gpd.GeoSeries([geom], crs=source_crs).to_crs(target_crs).iloc[0]\n",
    "\n",
    "        pr_minx, pr_miny, pr_maxx, pr_maxy = geom.bounds\n",
    "        search_bbox = (pr_minx, pr_miny, pr_maxx, pr_maxy)\n",
    "\n",
    "        # 1. Filter candidates\n",
    "        candidates = lizard_z_rtree.query(search_bbox)\n",
    "        \n",
    "        # 2. Refine\n",
    "        for bbox, lizard_idx in candidates:\n",
    "            geo = legless_gdf.loc[lizard_idx].geometry\n",
    "            if geom.contains(geo):\n",
    "                row = legless_gdf.loc[lizard_idx]\n",
    "                lizards_found.append({\n",
    "                    'Latitude': row['Latitude'],\n",
    "                    'Longitude': row['Longitude']\n",
    "                })\n",
    "\n",
    "    df_q1 = pd.DataFrame(lizards_found)\n",
    "    if not df_q1.empty:\n",
    "        initial_count = len(df_q1)\n",
    "        df_q1 = df_q1.drop_duplicates(subset=['Latitude', 'Longitude'])\n",
    "        final_count = len(df_q1)\n",
    "        \n",
    "        if initial_count > final_count:\n",
    "            print(f\"Removed {initial_count - final_count} duplicate sightings.\")\n",
    "            \n",
    "        print(f\"Final Count (Legless Lizards in Pine Ridge): {final_count}\")\n",
    "        \n",
    "        output_file = os.path.join(output_dir, 'Query1_Lizards_in_PineRidge.csv')\n",
    "        df_q1.to_csv(output_file, index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"Final Count: 0\")\n",
    "\n",
    "def run_query_2_packed(wetland_z_rtree, wetlands_gdf, protected_areas_gdf):\n",
    "    print(\"\\n--- Query 2 (Packed R-Tree) ---\")\n",
    "    target_parks = protected_areas_gdf[protected_areas_gdf['dcdbtenure'].isin(['State Forest', 'National Park'])]\n",
    "    wetlands_inside_data = []\n",
    "\n",
    "    source_crs_q2 = protected_areas_gdf.crs\n",
    "    target_crs_q2 = wetlands_gdf.crs \n",
    "\n",
    "    for idx, park in target_parks.iterrows():\n",
    "        geom = park.geometry\n",
    "        if source_crs_q2 != target_crs_q2:\n",
    "            geom = gpd.GeoSeries([geom], crs=source_crs_q2).to_crs(target_crs_q2).iloc[0]\n",
    "\n",
    "        p_minx, p_miny, p_maxx, p_maxy = geom.bounds\n",
    "        search_bbox = (p_minx, p_miny, p_maxx, p_maxy)\n",
    "        \n",
    "        # 1. Filter candidates\n",
    "        candidates = wetland_z_rtree.query(search_bbox)\n",
    "        \n",
    "        # 2. Refine\n",
    "        for wet_bbox, wet_data in candidates:\n",
    "            wet_geo = wet_data.geometry\n",
    "            if geom.contains(wet_geo):\n",
    "                wetlands_inside_data.append({\n",
    "                    'wname': wet_data['wname'],\n",
    "                    'estatename': park['estatename'],\n",
    "                    'dcdbtenure': park['dcdbtenure']\n",
    "                })\n",
    "\n",
    "    df_q2 = pd.DataFrame(wetlands_inside_data)\n",
    "    if not df_q2.empty:\n",
    "        initial_count = len(df_q2)\n",
    "        df_q2 = df_q2.drop_duplicates(subset=['wname'])\n",
    "        final_count = len(df_q2)\n",
    "        \n",
    "        if initial_count > final_count:\n",
    "            print(f\"Removed {initial_count - final_count} duplicate wetlands.\")\n",
    "            \n",
    "        print(f\"Found {final_count} unique wetlands inside State/National Parks.\")\n",
    "        \n",
    "        output_file = os.path.join(output_dir, 'Query2_Wetlands_in_Parks.csv')\n",
    "        df_q2.to_csv(output_file, index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"Found 0 wetlands.\")\n",
    "\n",
    "def run_query_3_packed(wetland_z_rtree, wetlands_gdf, platypus_gdf):\n",
    "    print(\"\\n--- Query 3 (Packed R-Tree - Nearest Neighbor) ---\")\n",
    "    print(f\"Processing {len(platypus_gdf)} platypus sightings against {len(wetlands_gdf)} wetlands.\")\n",
    "    \n",
    "    results_q3 = []\n",
    "\n",
    "    source_crs_q3 = platypus_gdf.crs\n",
    "    target_crs_q3 = wetlands_gdf.crs\n",
    "    \n",
    "    # --- Safety Check for CRS Mismatch ---\n",
    "    is_geographic = False\n",
    "    if target_crs_q3 and hasattr(target_crs_q3, 'is_geographic'):\n",
    "        is_geographic = target_crs_q3.is_geographic\n",
    "    \n",
    "    metric_crs = \"EPSG:3577\" \n",
    "    MAX_RADIUS_LIMIT = 60.0 if is_geographic else 6000000.0\n",
    "\n",
    "    for idx, platypus in platypus_gdf.iterrows():\n",
    "        p_point = platypus.geometry\n",
    "        \n",
    "        if source_crs_q3 != target_crs_q3:\n",
    "            p_point = gpd.GeoSeries([p_point], crs=source_crs_q3).to_crs(target_crs_q3).iloc[0]\n",
    "\n",
    "        px, py = p_point.x, p_point.y\n",
    "        \n",
    "        # Iterative search: Start small, expand if needed\n",
    "        radius = 0.1 if is_geographic else 10000.0\n",
    "        found_nearest = False\n",
    "        min_dist = float('inf')\n",
    "        nearest_wetland_name = None\n",
    "        nearest_wetland_geo = None\n",
    "        \n",
    "        while not found_nearest and radius <= MAX_RADIUS_LIMIT:\n",
    "            search_bbox = (px - radius, py - radius, px + radius, py + radius)\n",
    "            candidates = wetland_z_rtree.query(search_bbox)\n",
    "            \n",
    "            if candidates:\n",
    "                for wet_bbox, wet_data in candidates:\n",
    "                    wet_geo = wet_data.geometry\n",
    "                    dist = p_point.distance(wet_geo)\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        nearest_wetland_name = wet_data['wname']\n",
    "                        nearest_wetland_geo = wet_geo\n",
    "                \n",
    "                if min_dist < radius:\n",
    "                    found_nearest = True\n",
    "                else:\n",
    "                    radius *= 2\n",
    "            else:\n",
    "                radius *= 2\n",
    "        \n",
    "        final_distance = min_dist\n",
    "        if is_geographic and nearest_wetland_geo is not None:\n",
    "            p_series = gpd.GeoSeries([p_point], crs=target_crs_q3).to_crs(metric_crs)\n",
    "            w_series = gpd.GeoSeries([nearest_wetland_geo], crs=target_crs_q3).to_crs(metric_crs)\n",
    "            final_distance = p_series.distance(w_series).iloc[0]\n",
    "        elif min_dist == float('inf'):\n",
    "            final_distance = None\n",
    "            \n",
    "        results_q3.append({\n",
    "            'Platypus_ID': idx,\n",
    "            'Latitude': platypus['Latitude'],\n",
    "            'Longitude': platypus['Longitude'],\n",
    "            'Nearest_Wetland': nearest_wetland_name,\n",
    "            'Distance (m)': final_distance\n",
    "        })\n",
    "\n",
    "    df_q3 = pd.DataFrame(results_q3)\n",
    "    \n",
    "    initial_count = len(df_q3)\n",
    "    df_q3 = df_q3.drop_duplicates(subset=['Latitude', 'Longitude'])\n",
    "    final_count = len(df_q3)\n",
    "\n",
    "    if initial_count > final_count:\n",
    "        print(f\"Removed {initial_count - final_count} duplicate platypus sightings.\")\n",
    "\n",
    "    print(df_q3.head())\n",
    "    print(f\"Processed {final_count} unique platypus sightings.\")\n",
    "    \n",
    "    output_file = os.path.join(output_dir, 'Query3_Platypus_Nearest_Wetland.csv')\n",
    "    df_q3.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Execute\n",
    "if 'lizard_z_rtree' in globals() and 'wetland_z_rtree' in globals():\n",
    "    run_query_1_packed(lizard_z_rtree, legless_gdf, protected_areas_gdf)\n",
    "    run_query_2_packed(wetland_z_rtree, wetlands_gdf, protected_areas_gdf)\n",
    "    run_query_3_packed(wetland_z_rtree, wetlands_gdf, platypus_gdf)\n",
    "else:\n",
    "    print(\"Error: Packed R-Trees not found. Please run the 'Build Packed R-Trees' cell first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
